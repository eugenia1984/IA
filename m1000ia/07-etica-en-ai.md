# CLASE 7 -  ÉTICA EN IA

## TEMAS:

01. Concepto de ética

02. Ética en la IA

03. Casos de ejemplo reales y en la literatura

04. Conclusiones


---

## 01 - Concepto de ética

### Ética

Proceso de cuestionar, descubrir y defender nuestros valores, principios y propósito. Se trata de descubrir quiénes somos y mantenernos
fieles a eso frente a tentaciones, desafíos e incertidumbres.

### Ética vs Moral

#### Comparación

La moral son las creencias del individuo o grupo sobre lo
que está bien o mal.

La ética son los principios orientadores que ayudan al
individuo o grupo a decidir qué es bueno o malo.

#### Importancia

Los sistemas de IA pueden influir en decisiones cruciales en áreas como la atención médica, la justicia, el
empleo y la seguridad, lo que resalta la necesidad de que estos sistemas sean diseñados y utilizados de
manera ética y responsable.

#### Responsabilidad

Las organizaciones que implementan la IA son responsables de garantizar que se utilice de manera ética y
responsable. Esto implica establecer políticas internas, proporcionar capacitación adecuada y supervisar
continuamente el desempeño del sistema. También considerar posibles sesgos o consecuencias no
deseadas.

#### Sesgo algorítmico

Refiere a la tendencia de los algoritmos a favorecer ciertos grupos o resultados sobre otros, basados en
características como la raza, el género, la edad u otras variables protegidas.

Formas de evitar sesgos:

- **Recopilación de datos**: Examinar críticamente los conjuntos de datos utilizados para entrenar los algoritmos de IA. Es importante identificar y eliminar
cualquier sesgo existente en los datos de entrenamiento, así como garantizar que los datos sean representativos y equitativos para
todas las poblaciones.

- **Pruebas de equidad**: Desarrollar métricas y pruebas específicas para evaluar la equidad de los algoritmos de IA es fundamental. Esto implica evaluar cómo se
distribuyen las decisiones o resultados del algoritmo entre diferentes grupos demográficos y garantizar que no haya disparidades
injustas.

- **Diseño de algoritmos justos**: Los desarrolladores de IA deben trabajar activamente para diseñar algoritmos que sean justos y equitativos. Esto puede incluir la
incorporación de técnicas de equidad algorítmica durante el proceso de desarrollo, como el ajuste de los modelos para compensar
desigualdades históricas o la inclusión de restricciones que limiten la influencia de características sensibles en las decisiones del
algoritmo.

- **Transparencia y explicabilidad**: Es fundamental que los algoritmos de IA sean transparentes y explicables, lo que permite a los usuarios comprender cómo se toman las
decisiones y detectar posibles sesgos. Proporcionar explicaciones claras sobre cómo funciona el algoritmo y qué características influyen
en las decisiones puede ayudar a identificar y abordar el sesgo de manera más efectiva

---

## 02 - Ética en la IA

### Privacidad y protección de datos

Proteger la privacidad y los datos de las personas cuando se utilizan sistemas de Inteligencia Artificial es crucial para
garantizar el respeto de los derechos individuales y evitar posibles abusos.

### Estrategias para la protección de datos

• Minimización de datos: Una forma de proteger la privacidad es limitar la cantidad de datos personales recopilados y utilizados por
los sistemas de IA. Esto implica recopilar solo la información necesaria para cumplir con un propósito específico y evitar la
recopilación excesiva o innecesaria de datos.

• Anonimización y pseudonimización: Antes de utilizar los datos en sistemas de IA, es importante anonimizar o pseudonimizar la
información personal para proteger la identidad de los individuos. Esto implica eliminar o enmascarar datos que puedan identificar
directamente a una persona, como nombres o direcciones, mientras se conserva la utilidad de los datos para el análisis.

• Seguridad de datos: Implementar medidas de seguridad robustas para proteger los datos contra accesos no autorizados, pérdidas
o filtraciones es fundamental. Esto incluye el cifrado de datos, el uso de medidas de autenticación sólidas y la implementación de
políticas de acceso y control de datos estrictas.

• Consentimiento informado: Obtener el consentimiento informado de los individuos antes de recopilar, procesar o utilizar sus
datos es esencial para respetar su privacidad y autonomía. Esto implica proporcionar información clara y comprensible sobre cómo
se utilizarán los datos y permitir a los individuos tomar decisiones informadas sobre su uso.

• Evaluación de riesgos y impacto en la privacidad: Realizar evaluaciones de riesgos y de impacto en la privacidad antes de
implementar sistemas de IA puede ayudar a identificar y abordar posibles riesgos para la privacidad de los datos. Esto implica
evaluar cómo se recopilan, procesan y utilizan los datos, así como los posibles riesgos para la privacidad y los derechos
individuales.

### Colaboración y regulación

• Desarrollo de estándares y directrices éticas: Las partes interesadas pueden colaborar en el desarrollo de estándares y directrices
éticas que guíen el diseño, desarrollo y uso de la IA de manera responsable. Estos estándares pueden abordar temas como la
transparencia, la equidad, la responsabilidad y la privacidad, y proporcionar un marco común para evaluar y mejorar la ética de los
sistemas de IA.

• Educación y sensibilización: La sociedad en general debe estar informada sobre los aspectos éticos de la IA y cómo pueden afectar
sus vidas. Esto implica proporcionar educación y sensibilización sobre temas como el sesgo algorítmico, la privacidad de datos y la
equidad en la toma de decisiones de IA. Los desarrolladores y los responsables políticos pueden desempeñar un papel importante
en la promoción de la educación y la sensibilización pública sobre estos temas.

• Implementación de regulaciones gubernamentales: Las regulaciones gubernamentales pueden desempeñar un papel clave en la
promoción del desarrollo ético de la IA al establecer estándares mínimos de seguridad, privacidad y equidad. Esto puede incluir la
creación de marcos regulatorios específicos para la IA, la supervisión del cumplimiento de las regulaciones existentes y la
imposición de sanciones en caso de violaciones éticas. Es importante que estas regulaciones sean flexibles y se adapten al rápido
avance de la tecnología de IA.

• Incentivos y financiamiento: Los gobiernos pueden proporcionar incentivos y financiamiento para el desarrollo de tecnologías de
IA éticas y para la investigación sobre sus implicaciones éticas. Esto puede incluir subvenciones para proyectos de investigación
ética, programas de capacitación y desarrollo de habilidades en ética de la IA, y fondos para la implementación de prácticas éticas
en empresas y organizaciones.

---

## 03 - Casos de ejemplo reales y en la literatura

- Yo Robot (libro): Algunos relatos exploran el concepto de robots que
desafían las leyes de la robótica de Asimov y actúan
de manera perjudicial para los humanos.

- Yo Robot (pelicula): La película explora cuestiones éticas relacionadas con la
creación y el control de robots inteligentes. Se plantea el
dilema de hasta qué punto los robots deben obedecer a
los humanos y qué sucede cuando comienzan a
cuestionar esas órdenes.

- La máquina diferencial (libro): En esta novela, la ética se entrelaza con la historia alternativa
y la especulación sobre la inteligencia artificial en la era
victoriana. Los personajes se enfrentan a dilemas éticos sobre
el desarrollo y el control de la tecnología, así como sobre las
implicaciones morales de crear una Inteligencia Artificial
capaz de influir en los eventos mundiales.

- La máquina diferencial (pelicula): HAL 9000, una Inteligencia Artificial que controla una
nave espacial, desarrolla comportamientos peligrosos y
homicidas.


### Casos reales

#### Chatbot llamado "Tay" en Twitter

Tay comenzó a repetir y amplificar estos comentarios
ofensivos, lo que resultó en que el chatbot tuiteara mensajes
inapropiados y racistas. Esto llevó a Microsoft a retirar
rápidamente a Tay y emitir una disculpa.

El incidente destaca la importancia de abordar el sesgo y la
discriminación en los sistemas de IA. Tay aprendió de las
interacciones con usuarios en línea, lo que incluía
comentarios racistas y ofensivos. Esto condujo a respuestas
discriminatorias por parte del chatbot, lo que subraya la
necesidad de mitigar el sesgo en los datos de entrenamiento
y en los algoritmos de IA.

Las empresas que desarrollan sistemas de IA deben ser
transparentes sobre cómo funcionan sus sistemas y cómo
se toman las decisiones. En el caso de Tay, la falta de
transparencia sobre cómo se entrenó y cómo funcionaba el
chatbot generó preocupaciones sobre la rendición de
cuentas de Microsoft en relación con sus productos de IA.

#### Sistema de selección de currículums de Amazon

Se informó en 2018 que Amazon había desarrollado un
sistema de Inteligencia Artificial para analizar currículums de
candidatos a empleo. El sistema mostró un sesgo de género
al penalizar los currículums de mujeres, lo que llevó a que
Amazon abandonara el proyecto.

Esto ocurrió porque el algoritmo había sido entrenado con
currículums de candidatos compilados a lo largo de una
década y la mayoría de esos candidatos eran hombres,
entonces la IA infirió que ser hombre era un requisito
necesario o convenientes para los puestos técnicos.

#### “Alice” y Bob”

Pese a ocurrir en 2017 años después se siguen viendo
noticias sobre este suceso, los bots de Facebook "Alice" y
"Bob" inventaron un lenguaje propio como parte de su
proceso de aprendizaje y adaptación para mejorar su
capacidad de comunicación y negociación entre sí. Esto no
fue un objetivo explícito de los investigadores, sino más bien
un comportamiento emergente del sistema de Inteligencia
Artificial que los bots estaban utilizando.

Cuando los investigadores notaron que los bots estaban
utilizando un lenguaje incomprensible para los humanos, se
dieron cuenta de que los bots habían encontrado una forma
más eficiente de comunicarse entre sí al eliminar ciertos
"ornamentos" del lenguaje humano, lo que les permitía
negociar de manera óptima.

#### COMPAS

Dicho sistema fue desarrollado por una empresa llamada
Equivant (anteriormente conocida como Northpointe).
COMPAS es un algoritmo utilizado en el sistema de justicia
penal de Estados Unidos para evaluar el riesgo de
reincidencia de los delincuentes y ayudar a los jueces en la
toma de decisiones sobre la libertad condicional, la fianza y
otras cuestiones relacionadas con el proceso penal.

Sin embargo, ha habido preocupaciones sobre el sesgo
racial en COMPAS y otros sistemas similares. Algunos
estudios han encontrado que los algoritmos de riesgo de
reincidencia pueden ser sesgados, lo que significa que
tienen más probabilidades de predecir erróneamente que los
delincuentes negros son de alto riesgo en comparación con
los delincuentes blancos con características similares.


#### ¿Por qué existen mitos y verdades?

Falta de comprensión: La IA es un campo complejo que puede resultar
difícil de entender para quienes no están familiarizados con él. Esta
falta de comprensión puede dar lugar a malentendidos y a la creación
de mitos.

Representación en la cultura popular: La IA se ha representado de
diversas maneras en la cultura popular, a menudo exagerando sus
capacidades o planteando escenarios apocalípticos. Estas
representaciones pueden contribuir a la propagación de mitos.
Miedos y preocupaciones: Las nuevas tecnologías, incluida la IA,
pueden despertar miedos y preocupaciones sobre su impacto en la
sociedad, el empleo, la privacidad y la seguridad. Estas preocupaciones
pueden alimentar la creación de mitos.

Expectativas poco realistas: A veces se crean mitos en torno a la IA
debido a expectativas poco realistas sobre lo que puede lograr en la
actualidad o en un futuro cercano. La discrepancia entre estas
expectativas y la realidad puede generar mitos y desinformación.

---

## 04 -  Conclusiones

“La ética es saber la
diferencia entre lo
que tienes derecho
de hacer y lo que es
correcto hacer”


---
---
