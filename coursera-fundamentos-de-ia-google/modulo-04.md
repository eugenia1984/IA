# MODULO 4 - UTILIZA LA AI DE FORMA RESPONSABLE

Usa la IA de forma responsable mitigando los sesgos injustos y las imprecisiones. Aprende a aplicar un marco de daños de la IA a ejemplos de escenarios laborales y a reconocer los riesgos de seguridad al usar la IA en el trabajo. Al final de este módulo, comprenderás cómo utilizar la IA de forma responsable y eficaz, y dispondrás de una lista de verificación que te ayudará a hacerlo.

## Objetivos de aprendizaje

- Identifica los daños de la IA y su posible impacto en usuarios y estructuras sociales.

- Reconoce las posibles repercusiones del uso de la IA en la privacidad y la seguridad.

- Describe cómo se refleja el sesgo de los datos en los modelos modernos de IA.

- Explica los riesgos y sesgos inherentes a la IA moderna y las mejores prácticas para abordarlos.

---
---

# Reconoce los sesgos de los datos y daños de la IA 


## Introducción al módulo 4: Utiliza la IA de forma responsable

Asegúrate de utilizar la IA de forma responsable, ética, y para obtener buenos resultados.

¡Hola! Me complace presentarles nuevos conceptos que les ayudará a aprender a utilizar la IA de forma responsable. Aprender a utilizar la IA responsablemente es una parte crucial de experimentar con esta tecnología y usarla. La IA responsable es el principio de desarrollar y usar la IA de manera ética con la intención de beneficiar a las personas y a la sociedad, evitando al mismo tiempo perjudicarlas. Para garantizar que las personas reciban un trato justo y respetuoso, los usuarios de IA deben ser conscientes de las limitaciones de las herramientas de IA y comprometerse a utilizarlas éticamente. Un usuario de IA es alguien que aprovecha la IA para completar una tarea personal o profesional, como editar textos para una campaña de marketing, generar ideas para una recaudación de fondos sin fines de lucro o descubrir formas más eficaces de utilizar una tecnología determinada. La IA puede realizar muchas tareas que ayudan a que el trabajo sea más productivo, eficiente o atractivo. Pero seamos claros, la IA no es perfecta. Los humanos son creativos, lógicos y compasivos. Tenemos capacidad de razonamiento crítico y comprensión contextual de nuestro entorno de la que carecen los sistemas de IA. Considera cómo funciona el piloto automático en un avión. El piloto automático navega del punto A al punto B, pero el avión sigue necesitando un piloto humano para tomar decisiones complejas. Por ejemplo, si el clima obliga al avión a hacer un aterrizaje de emergencia, el piloto será quien gestione esa situación y aterrice con seguridad el avión. En este escenario, el piloto automático es el sistema y el piloto es el usuario. El piloto automático puede manejar muchos de los aspectos más técnicos de mantener el avión en el aire, pero en general volar el avión con seguridad es responsabilidad de los pilotos. Del mismo modo, las herramientas de IA pueden ayudar con muchas tareas básicas en el trabajo. La IA puede utilizarse para generar ideas para un nuevo producto, esbozar un comunicado de prensa, sugerir preguntas para hacer durante un grupo focal y más, pero no puede realizar tareas de nivel superior como hacer comentarios personalizados a un empleado o emitir juicio sobre qué candidato contratar o proporcionar terapia a un paciente. La IA funciona mejor cuando se utiliza como complemento de nuestras habilidades y capacidades humanas únicas Como miembro del equipo de Innovación responsable, utilizo mis capacidades humanas para conectar con mis colegas, motivar a los compañeros de equipo e impulsar la innovación responsable. M

e llamo Emilio y voy a ayudarte a aprender qué significa usar la IA de manera responsable. En esta parte del curso aprenderás sobre los sesgos que existen en los modelos de IA. 

A continuación, examinarás los tipos de daños que se asocian a la IA y la importancia de vincular el uso de la IA con capacidades humanas como el pensamiento crítico y la toma responsable de decisiones. Por último, obtendrás algunos consejos para mantener la privacidad y seguridad mientras experimentas o utilizas herramientas de IA. ¡Empecemos!

---

## :tv: Comprende los sesgos de la IA

a IA es una **herramienta inspiradora que permite vivir nuevas experiencias, oportunidades y logros**. 

Por ejemplo, la IA se utiliza para ayudar a los automóviles autoconducidos a detectar peatones en una carretera muy transitada y predecir la presencia y gravedad de una enfermedad. Sin embargo, **el hecho de que la IA sea beneficiosa no es un hecho**. Como usuario consciente de los s**esgos potenciales de la IA y sus limitaciones**, puedes ayudar a garantizar resultados responsables en lugar de perjudiciales. 

**Los modelos de IA se entrenan con datos creados por humanos, por lo que se componen de valores y están sujetos a sesgos**. **A veces también pueden producir resultados inexactos**. Dado que un modelo de IA se entrena con un conjunto de datos para reconocer patrones y realizar tareas, **el modelo es tan bueno como los datos que recibe**. **El resultado de la IA puede verse afectado tanto por el sesgo sistémico como por el sesgo de los datos**. 

Exploremos ahora cada uno de ellos:

1. En primer lugar, el **sesgo sistémico** es **una tendencia mantenida por las instituciones que favorece o perjudica determinados resultados o grupos**. El sesgo sistémico existe dentro de los sistemas sociales como sanidad, derecho educación, política, etc. Aunque las personas que diseñan y entrenan un modelo de IA piensan que están utilizando datos de alta calidad, los datos ya pueden estar sesgados porque los seres humanos están influenciados por sesgos sistémicos.

2. El **sesgo de los datos** es **una circunstancia en la que los errores o perjuicios sistémicos conducen a información injusta o inexacta, dando lugar a resultados sesgados**. Tal vez estés desarrollando una presentación de trabajo, le pides a un generador de imágenes de IA que cree una foto de un director general. Todas las imágenes generadas parecen ser hombres blancos. Basándonos en este resultado, se podría suponer que todos los directores generales son hombres blancos. Obviamente, estos datos están sesgados. Aun así, cuanto más se entrena un modelo de IA con imágenes de hombres blancos como directores generales, más probable es que estos modelos generen resultados igualmente sesgados. Por lo tanto, cuanto más representativos sean los datos de una mayor variedad de personas, más integrador será el resultado de la generación de imágenes.

Al igual que los modelos de IA reflejan los sesgos de los datos utilizados para entrenarlos, también reflejan los valores de las personas que los diseñan. En otras palabras, **los modelos de IA están cargados de valores**. Por ejemplo, puede que un ingeniero de IA quiera ayudar a crear formas más sustentables de generar energía. El ingeniero podría utilizar la IA para construir una herramienta que permite a los proveedores de energía aumentar su uso de recursos renovables. En este caso, la herramienta de IA se creó a partir de la idea de que la sociedad puede y debe aprovechar al máximo la energía solar y las fuentes de energía eólica, que es un reflejo de los valores del ingeniero. Este enfoque significa que la herramienta de IA no es intrínsecamente neutral desde el punto de vista de los valores. Otras personas pueden tener valores diferentes sobre la generación de energía que no se reflejan en esta herramienta de IA concreta. 

Como la mayoría de los aspectos de la tecnología emergente, la IA no es un sistema perfecto. En la actualidad, ofrece tanto oportunidades y retos, por lo que su uso responsable requiere un pensamiento crítico y la comprensión de cómo los datos pueden estar sesgados.

---

## :tv: Identifica daños de la IA


Para limitar los sesgos, los cambios y las imprecisiones, los modelos de IA requieren la intervención humana, como volver a entrenar los modelos con conjuntos de datos más diversos y continuar ajustándolos con frecuencia. Los humanos también deben tener en cuenta los daños involuntarios asociados al uso de estas herramientas de IA. Examinemos algunos de los tipos de daños que la IA puede causar si se utiliza de forma irresponsable. 

- Primero está el **daño distributivo**. El daño distributivo es **un daño que se produce cuando el uso o el comportamiento de un sistema de IA niega oportunidades, recursos o información en ámbitos que afectan el bienestar de una persona**. Por ejemplo, si las herramientas de IA no proporcionan la misma información a todos, a algunas personas se les puede negar acceso a la educación, sanidad, vivienda justa u otras oportunidades. Tal vez un administrador de la propiedad de un complejo de apartamentos utiliza una herramienta de IA para examinar las solicitudes para posibles inquilinos. Esta herramienta de IA utiliza los nombres y otra información identificatoria sobre estas solicitudes para ayudar a comprobar los antecedentes. Un solicitante se considera de riesgo debido a una baja puntuación crediticia, por lo que se le niega el apartamento y pierde la tasa de solicitud. Más tarde, el administrador de la propiedad se da cuenta de que el software había identificado erróneamente al solicitante había realizado una verificación de antecedentes a la persona equivocada. En este ejemplo, el solicitante ha sufrido un daño distributivo porque se le negó la oportunidad y perdió recursos, que ambos afectando su bienestar.

- Otro tipo de daño que puede causar la IA es el **daño a la calidad del servicio**. El daño a la calidad del servicio **es una circunstancia en la que las herramientas de IA no funcionan tan bien para determinados grupos de personas en función de su identidad**. Cuando la tecnología de reconocimiento de voz fue desarrollada por primera vez, los datos de entrenamiento no tenían muchos ejemplos de los patrones del habla de las personas con discapacidades, por lo que los dispositivos a menudo tenían dificultades para analizar este tipo de discurso, pero esta tecnología sigue evolucionando.

- El siguiente tipo de perjuicio es **daño de representación**, que es **el refuerzo de la subordinación de grupos sociales basado en su identidad por parte de una herramienta de IA**. Por ejemplo, la IA que impulsa una aplicación de traducción de idiomas puede asociar ciertas palabras con rasgos femeninos o masculinos, y elegir traducciones específicas para cada género con base en esos supuestos. Ahora, esto es perjudicial porque el resultado puede ser la eliminación o alienación de grupos sociales debido a prejuicios incorporados.

- Otro tipo de daño asociado a la IA es el **daño al sistema social**. Este daño se refiere a **los efectos sociales a nivel macro que amplifican las disparidades existentes de clases, poder o privilegio, o causar daños físicos como resultado del desarrollo o el uso de herramientas de IA**. A medida que las imágenes generadas por la IA se vuelven más realistas, hay preocupación por la propagación de la desinformación, incluyendo los "Deepfakes". Los "Deepfakes" son fotos o videos falsos generados por la IA de personas reales diciendo o haciendo cosas que no hicieron. Un ejemplo de daño a un sistema social podría ser si un "Deepfake" de un candidato al consejo escolar mostrara a esa persona diciendo algo que no dijo. Si se volviera viral y causara que perdiera las elecciones, eso afectaría las perspectivas de los votantes, la forma en que los padres se sienten acerca de su distrito escolar y la comunidad en general. Porque habría desinformación que se difunde a gran escala, esto sería un daño al sistema social. Afortunadamente, se está creando tecnología nueva para detectar los "Deepfakes". Algunas herramientas de generación de imágenes están colocando marcas de agua digitales en imágenes y videos generados por la IA para indicar quién los creó. Con el tiempo, las falsificaciones deberían volverse más fáciles de identificar para las computadoras. Los usuarios de la IA deben ser conscientes de la dificultad de distinguir entre imágenes generadas por la IA e imágenes reales, y las consecuencias de crear estos "Deepfakes".

- A veces la gente puede compartir información privada con una herramienta de IA que podría ser utilizada erróneamente por otros, como bloquear a alguien de una cuenta en línea o vigilarlo. Estos son ejemplos de **daño interpersonal**, que es **el uso de la tecnología para crear una desventaja para determinadas personas que afecta negativamente sus relaciones con los demás o causa una pérdida del sentido de de su sentido de identidad y voluntad**.

Todos estos daños son ejemplos de cómo el uso irresponsable de la tecnología puede afectar negativamente las personas y las comunidades. Si se utiliza sin intervención intervención humana o pensamiento crítico, la IA puede reforzar los prejuicios sistémicos, lo que conduce a una distribución injusta de los recursos, la perpetuación de estereotipos peligrosos, o el refuerzo de dinámicas de poder en curso. La buena noticia es que las herramientas de IA están evolucionando rápidamente. basándose en los comentarios de los usuarios. Por eso, ser consciente del daño potencial y resultados negativos es un primer paso para utilizar la IA de forma responsable.

---
---

# IA para el bienestar social 

---
---

# Revisión: Utiliza la IA de forma responsable

---
---
