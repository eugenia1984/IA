# MODULO 4 - UTILIZA LA AI DE FORMA RESPONSABLE

Usa la IA de forma responsable mitigando los sesgos injustos y las imprecisiones. Aprende a aplicar un marco de daños de la IA a ejemplos de escenarios laborales y a reconocer los riesgos de seguridad al usar la IA en el trabajo. Al final de este módulo, comprenderás cómo utilizar la IA de forma responsable y eficaz, y dispondrás de una lista de verificación que te ayudará a hacerlo.

## Objetivos de aprendizaje

- Identifica los daños de la IA y su posible impacto en usuarios y estructuras sociales.

- Reconoce las posibles repercusiones del uso de la IA en la privacidad y la seguridad.

- Describe cómo se refleja el sesgo de los datos en los modelos modernos de IA.

- Explica los riesgos y sesgos inherentes a la IA moderna y las mejores prácticas para abordarlos.

---
---

# Reconoce los sesgos de los datos y daños de la IA 


## Introducción al módulo 4: Utiliza la IA de forma responsable

Asegúrate de utilizar la IA de forma responsable, ética, y para obtener buenos resultados.

¡Hola! Me complace presentarles nuevos conceptos que les ayudará a aprender a utilizar la IA de forma responsable. Aprender a utilizar la IA responsablemente es una parte crucial de experimentar con esta tecnología y usarla. La IA responsable es el principio de desarrollar y usar la IA de manera ética con la intención de beneficiar a las personas y a la sociedad, evitando al mismo tiempo perjudicarlas. Para garantizar que las personas reciban un trato justo y respetuoso, los usuarios de IA deben ser conscientes de las limitaciones de las herramientas de IA y comprometerse a utilizarlas éticamente. Un usuario de IA es alguien que aprovecha la IA para completar una tarea personal o profesional, como editar textos para una campaña de marketing, generar ideas para una recaudación de fondos sin fines de lucro o descubrir formas más eficaces de utilizar una tecnología determinada. La IA puede realizar muchas tareas que ayudan a que el trabajo sea más productivo, eficiente o atractivo. Pero seamos claros, la IA no es perfecta. Los humanos son creativos, lógicos y compasivos. Tenemos capacidad de razonamiento crítico y comprensión contextual de nuestro entorno de la que carecen los sistemas de IA. Considera cómo funciona el piloto automático en un avión. El piloto automático navega del punto A al punto B, pero el avión sigue necesitando un piloto humano para tomar decisiones complejas. Por ejemplo, si el clima obliga al avión a hacer un aterrizaje de emergencia, el piloto será quien gestione esa situación y aterrice con seguridad el avión. En este escenario, el piloto automático es el sistema y el piloto es el usuario. El piloto automático puede manejar muchos de los aspectos más técnicos de mantener el avión en el aire, pero en general volar el avión con seguridad es responsabilidad de los pilotos. Del mismo modo, las herramientas de IA pueden ayudar con muchas tareas básicas en el trabajo. La IA puede utilizarse para generar ideas para un nuevo producto, esbozar un comunicado de prensa, sugerir preguntas para hacer durante un grupo focal y más, pero no puede realizar tareas de nivel superior como hacer comentarios personalizados a un empleado o emitir juicio sobre qué candidato contratar o proporcionar terapia a un paciente. La IA funciona mejor cuando se utiliza como complemento de nuestras habilidades y capacidades humanas únicas Como miembro del equipo de Innovación responsable, utilizo mis capacidades humanas para conectar con mis colegas, motivar a los compañeros de equipo e impulsar la innovación responsable. M

e llamo Emilio y voy a ayudarte a aprender qué significa usar la IA de manera responsable. En esta parte del curso aprenderás sobre los sesgos que existen en los modelos de IA. 

A continuación, examinarás los tipos de daños que se asocian a la IA y la importancia de vincular el uso de la IA con capacidades humanas como el pensamiento crítico y la toma responsable de decisiones. Por último, obtendrás algunos consejos para mantener la privacidad y seguridad mientras experimentas o utilizas herramientas de IA. ¡Empecemos!

---

## :tv: Comprende los sesgos de la IA

a IA es una **herramienta inspiradora que permite vivir nuevas experiencias, oportunidades y logros**. 

Por ejemplo, la IA se utiliza para ayudar a los automóviles autoconducidos a detectar peatones en una carretera muy transitada y predecir la presencia y gravedad de una enfermedad. Sin embargo, **el hecho de que la IA sea beneficiosa no es un hecho**. Como usuario consciente de los s**esgos potenciales de la IA y sus limitaciones**, puedes ayudar a garantizar resultados responsables en lugar de perjudiciales. 

**Los modelos de IA se entrenan con datos creados por humanos, por lo que se componen de valores y están sujetos a sesgos**. **A veces también pueden producir resultados inexactos**. Dado que un modelo de IA se entrena con un conjunto de datos para reconocer patrones y realizar tareas, **el modelo es tan bueno como los datos que recibe**. **El resultado de la IA puede verse afectado tanto por el sesgo sistémico como por el sesgo de los datos**. 

Exploremos ahora cada uno de ellos:

1. En primer lugar, el **sesgo sistémico** es **una tendencia mantenida por las instituciones que favorece o perjudica determinados resultados o grupos**. El sesgo sistémico existe dentro de los sistemas sociales como sanidad, derecho educación, política, etc. Aunque las personas que diseñan y entrenan un modelo de IA piensan que están utilizando datos de alta calidad, los datos ya pueden estar sesgados porque los seres humanos están influenciados por sesgos sistémicos.

2. El **sesgo de los datos** es **una circunstancia en la que los errores o perjuicios sistémicos conducen a información injusta o inexacta, dando lugar a resultados sesgados**. Tal vez estés desarrollando una presentación de trabajo, le pides a un generador de imágenes de IA que cree una foto de un director general. Todas las imágenes generadas parecen ser hombres blancos. Basándonos en este resultado, se podría suponer que todos los directores generales son hombres blancos. Obviamente, estos datos están sesgados. Aun así, cuanto más se entrena un modelo de IA con imágenes de hombres blancos como directores generales, más probable es que estos modelos generen resultados igualmente sesgados. Por lo tanto, cuanto más representativos sean los datos de una mayor variedad de personas, más integrador será el resultado de la generación de imágenes.

Al igual que los modelos de IA reflejan los sesgos de los datos utilizados para entrenarlos, también reflejan los valores de las personas que los diseñan. En otras palabras, **los modelos de IA están cargados de valores**. Por ejemplo, puede que un ingeniero de IA quiera ayudar a crear formas más sustentables de generar energía. El ingeniero podría utilizar la IA para construir una herramienta que permite a los proveedores de energía aumentar su uso de recursos renovables. En este caso, la herramienta de IA se creó a partir de la idea de que la sociedad puede y debe aprovechar al máximo la energía solar y las fuentes de energía eólica, que es un reflejo de los valores del ingeniero. Este enfoque significa que la herramienta de IA no es intrínsecamente neutral desde el punto de vista de los valores. Otras personas pueden tener valores diferentes sobre la generación de energía que no se reflejan en esta herramienta de IA concreta. 

Como la mayoría de los aspectos de la tecnología emergente, la IA no es un sistema perfecto. En la actualidad, ofrece tanto oportunidades y retos, por lo que su uso responsable requiere un pensamiento crítico y la comprensión de cómo los datos pueden estar sesgados.

---

## :tv: Identifica daños de la IA


Para limitar los sesgos, los cambios y las imprecisiones, los modelos de IA requieren la intervención humana, como volver a entrenar los modelos con conjuntos de datos más diversos y continuar ajustándolos con frecuencia. Los humanos también deben tener en cuenta los daños involuntarios asociados al uso de estas herramientas de IA. Examinemos algunos de los tipos de daños que la IA puede causar si se utiliza de forma irresponsable. 

- Primero está el **daño distributivo**. El daño distributivo es **un daño que se produce cuando el uso o el comportamiento de un sistema de IA niega oportunidades, recursos o información en ámbitos que afectan el bienestar de una persona**. Por ejemplo, si las herramientas de IA no proporcionan la misma información a todos, a algunas personas se les puede negar acceso a la educación, sanidad, vivienda justa u otras oportunidades. Tal vez un administrador de la propiedad de un complejo de apartamentos utiliza una herramienta de IA para examinar las solicitudes para posibles inquilinos. Esta herramienta de IA utiliza los nombres y otra información identificatoria sobre estas solicitudes para ayudar a comprobar los antecedentes. Un solicitante se considera de riesgo debido a una baja puntuación crediticia, por lo que se le niega el apartamento y pierde la tasa de solicitud. Más tarde, el administrador de la propiedad se da cuenta de que el software había identificado erróneamente al solicitante había realizado una verificación de antecedentes a la persona equivocada. En este ejemplo, el solicitante ha sufrido un daño distributivo porque se le negó la oportunidad y perdió recursos, que ambos afectando su bienestar.

- Otro tipo de daño que puede causar la IA es el **daño a la calidad del servicio**. El daño a la calidad del servicio **es una circunstancia en la que las herramientas de IA no funcionan tan bien para determinados grupos de personas en función de su identidad**. Cuando la tecnología de reconocimiento de voz fue desarrollada por primera vez, los datos de entrenamiento no tenían muchos ejemplos de los patrones del habla de las personas con discapacidades, por lo que los dispositivos a menudo tenían dificultades para analizar este tipo de discurso, pero esta tecnología sigue evolucionando.

- El siguiente tipo de perjuicio es **daño de representación**, que es **el refuerzo de la subordinación de grupos sociales basado en su identidad por parte de una herramienta de IA**. Por ejemplo, la IA que impulsa una aplicación de traducción de idiomas puede asociar ciertas palabras con rasgos femeninos o masculinos, y elegir traducciones específicas para cada género con base en esos supuestos. Ahora, esto es perjudicial porque el resultado puede ser la eliminación o alienación de grupos sociales debido a prejuicios incorporados.

- Otro tipo de daño asociado a la IA es el **daño al sistema social**. Este daño se refiere a **los efectos sociales a nivel macro que amplifican las disparidades existentes de clases, poder o privilegio, o causar daños físicos como resultado del desarrollo o el uso de herramientas de IA**. A medida que las imágenes generadas por la IA se vuelven más realistas, hay preocupación por la propagación de la desinformación, incluyendo los "Deepfakes". Los "Deepfakes" son fotos o videos falsos generados por la IA de personas reales diciendo o haciendo cosas que no hicieron. Un ejemplo de daño a un sistema social podría ser si un "Deepfake" de un candidato al consejo escolar mostrara a esa persona diciendo algo que no dijo. Si se volviera viral y causara que perdiera las elecciones, eso afectaría las perspectivas de los votantes, la forma en que los padres se sienten acerca de su distrito escolar y la comunidad en general. Porque habría desinformación que se difunde a gran escala, esto sería un daño al sistema social. Afortunadamente, se está creando tecnología nueva para detectar los "Deepfakes". Algunas herramientas de generación de imágenes están colocando marcas de agua digitales en imágenes y videos generados por la IA para indicar quién los creó. Con el tiempo, las falsificaciones deberían volverse más fáciles de identificar para las computadoras. Los usuarios de la IA deben ser conscientes de la dificultad de distinguir entre imágenes generadas por la IA e imágenes reales, y las consecuencias de crear estos "Deepfakes".

- A veces la gente puede compartir información privada con una herramienta de IA que podría ser utilizada erróneamente por otros, como bloquear a alguien de una cuenta en línea o vigilarlo. Estos son ejemplos de **daño interpersonal**, que es **el uso de la tecnología para crear una desventaja para determinadas personas que afecta negativamente sus relaciones con los demás o causa una pérdida del sentido de de su sentido de identidad y voluntad**.

Todos estos daños son ejemplos de cómo el uso irresponsable de la tecnología puede afectar negativamente las personas y las comunidades. Si se utiliza sin intervención intervención humana o pensamiento crítico, la IA puede reforzar los prejuicios sistémicos, lo que conduce a una distribución injusta de los recursos, la perpetuación de estereotipos peligrosos, o el refuerzo de dinámicas de poder en curso. La buena noticia es que las herramientas de IA están evolucionando rápidamente. basándose en los comentarios de los usuarios. Por eso, ser consciente del daño potencial y resultados negativos es un primer paso para utilizar la IA de forma responsable.

---

## :tv: Emilio: Mi trayectoria hasta trabajar con la IA responsable

Hola. Soy Emilio. Trabajo en Google y soy gerente del Programa de innovación responsable. Siempre me preguntan: “Espera, ¿entonces eras licenciado en ciencias políticas y en español, ¿y ahora trabajas en IA? ¿Qué haces?”. Y mi mejor respuesta es que hago todo y nada. Soy gerente del programa. Me aseguro de que las cosas se hagan a tiempo. Me aseguro de que la gente trabaje en conjunto y colabore de manera eficiente, Conecto a los expertos en IA de áreas específicas de la IA como la percepción, la equidad, con equipos de desarrollo de productos que buscan incorporar esas prácticas recomendadas. Leí un libro realmente impactante sobre los peligros de automatizar algunos niveles de desigualdad sistémica. y creo que eso realmente me abrió los ojos no solo a las posibilidades de la IA, porque me considero un optimista tecnológico, sino a las ramificaciones de la aplicación de la IA sin enseñar completamente a la gente y sin comprender nosotros mismos que la implementamos, ¿cuáles son las ramificaciones de estos sistemas? Al pensar en tus propios antecedentes y tu propia educación, y de dónde vienes en tu cultura, tienes un cierto conjunto de experiencias que te han llevado a ser quien eres y que sirven de base para tus valores y creencias fundamentales. Lo mismo ocurre con la IA. Por ejemplo, yo soy del sur de California. Tengo predilección por el sol y las olas perfectas, ¿verdad? Creo que muchas personas lo tienen, pero yo en particular. Ahora bien, esos aspectos humanos pueden no ser directamente traducibles a un modelo de aprendizaje automático, pero dado que puedes equiparar experiencias con datos, los modelos de aprendizaje automático solo pueden aprender basándose en los datos que han incorporado, ya sea a través de conjuntos de datos históricos o los comentarios de los usuarios. Si podemos hacer que estos sistemas representes mejor a los usuarios a los que pretenden servir, creo que ayudará a servir a más gente. Muchas veces pienso: ¿cuál es la información que integra esos conjuntos de datos? ¿A quién se incluye y a quién se excluye? Algo en lo que pienso mucho son los sistemas de detección facial y las redes sociales. ¿Qué tan bien funcionan esos sistemas para la gente que se parece a mí, que tienen una piel más rica en melanina, o para personas que puedan tener piel más rica en melanina? ¿Y funciona de manera igualitaria en todo el espectro? ¿No funciona de manera igualitaria en todo el espectro? Creo que todos tenemos una responsabilidad personal al utilizar estas herramientas. Creo que las dos cosas que puedes hacer es comprobar los resultados de la herramienta que estés usando y, si vas a usar nuevos datos agregados al modelo, comprueba los datos. Asegúrate de que sea inclusivo. Asegúrate de que sea representativo de las distintas comunidades con las que esperas interactuar. Involúcrate. Da constantemente retroalimentación sobre cosas que no apruebas o que sí apruebas para que los grupos que están creando estos sistemas sepan cómo mejorar.

---

## :tv: Riesgos de seguridad y privacidad de la IA


Aprendiste que es importante ser consciente de los posibles daños de las herramientas de IA. 

Es igualmente importante asegurarse de que estás equipado con los conocimientos para tomar decisiones informadas sobre los datos, especialmente cuando se trata de privacidad y seguridad. 

**La privacidad es el derecho de un usuario a tener el control sobre la forma en que su información personal y datos se recopilan, almacenan y utilizan**. Se utiliza una variedad de información para entrenar modelos de IA, incluidos los conjuntos de datos y las entradas de los usuarios. Por ejemplo, los usuarios podrían revelar información privada durante sus interacciones con una herramienta de IA, y la información personal podría incluir nombres y direcciones, historial y registros médicos e información financiera y de pago. Si utilizas una herramienta de IA en tu trabajo, puedes decidir incluir información específica sobre un proyecto, las partes interesadas o tus clientes en una instrucción para la IA para que el resultado sea más específico para tu tarea. 

Pero utilizar una herramienta de IA de este modo puede suponer un riesgo para la seguridad. **La seguridad es el acto de salvaguardar la información personal y los datos privados, y garantizar la seguridad del sistema impidiendo el acceso no autorizado**. La mayoría de los líderes del sector informático creen que la IA generativa podría introducir nuevos riesgos para la seguridad, y que antes de que una organización implemente la IA generativa por primera vez, la organización deben establecer medidas de seguridad. 

**Como usuario, hay medidas que puedes tomar para proteger tu privacidad y seguridad, así como la de tu organización, compañeros de trabajo y socios comerciales**. 

- En primer lugar, antes de utilizar una herramienta de IA, conoce sus condiciones de uso o servicio, política de privacidad y cualquier riesgo asociado. Considera lo transparente que es una herramienta de IA sobre cómo recopila los datos de sus usuarios. Las herramientas de IA de confianza suelen construirse con sólidos equipos de seguridad y privacidad que han considerado detenidamente todo tipo de riesgos y se han esforzado en comunicarlos a los usuarios. Antes de aceptar las condiciones de servicio de un sitio web o una aplicación, sé consciente de qué datos se recopilan y cómo podrían utilizarse.

- Además, no introduzcas información personal o confidencial. La mayoría de las herramientas de IA funcionan adecuadamente sin datos personales específicos. Por lo tanto, cuando uses la IA, mantén en privado la información, como tu identidad, los datos presupuestarios de tu departamento o la dirección de correo electrónico.

- Del mismo modo, evita introducir información confidencial en una herramienta de IA para evitar que los datos estén disponibles para terceros durante una violación de seguridad o fuga de datos.

- Para personalizar tus resultados, siempre puedes editar los detalles más tarde. Muchas herramientas de IA utilizan encriptación y otras medidas para ayudar a proteger tu información, pero siempre debes asegurarte de proteger tu privacidad.

- Por último, mantente al día sobre las últimas herramientas. Conocer los nuevos avances en la IA puede ayudarte a comprender los riesgos a medida que surgen. Así que si planeas usar la IA con frecuencia, asegúrate de leer los últimos artículos de fuentes de noticias fiables, publicaciones académicas y universitarias, y expertos en la materia. Cuando se trata de la IA, la tecnología avanza y cambia casi a diario.

Por suerte, lo mismo sucede con las estrategias de seguridad. Como has aprendido, la privacidad y la seguridad son una parte importante del uso responsable de la IA. Y saber cómo mantener la seguridad tuya y de tu organización es una parte integrante de una IA responsable.

---

## :book: Sesgo, desvío y límite de conocimientos

Comprender a fondo los conceptos de la IA responsable, como el sesgo, la desviación y el límite de conocimientos, puede ayudarle a utilizar la IA de forma más ética y responsable. Con esta lectura aprenderá a utilizar las herramientas de IA de forma responsable y a comprender las implicaciones de los resultados injustos o imprecisos.

### Daños y prejuicios

Utilizar la IA de forma responsable requiere conocer sus sesgos inherentes. Los sesgos de los datos son circunstancias en las que errores sistémicos o prejuicios conducen a información injusta o inexacta, lo que da lugar a resultados sesgados. Los resultados sesgados pueden causar muchos tipos de daños a las personas y a la sociedad, entre ellos

- Daño distributivo: Daño que se produce cuando el uso o el comportamiento de un sistema de IA niega oportunidades, recursos o información en ámbitos que afectan al bienestar de una persona

Ejemplo: Si el administrador de un complejo de apartamentos utilizara una herramienta de IA que verificara los antecedentes de los posibles inquilinos, la herramienta de IA podría identificar erróneamente a un solicitante y considerarlo un riesgo por su baja puntuación crediticia. Podría denegársele un apartamento y perder la tasa de solicitud.

- Daños en la calidad del servicio: Circunstancia en la que las herramientas de IA no funcionan igual de bien para determinados grupos de personas en función de su identidad

Ejemplo: Cuando se desarrolló por primera vez la tecnología de reconocimiento del habla, los datos de entrenamiento no contenían muchos ejemplos de patrones de habla exhibidos por personas con discapacidad, por lo que los dispositivos a menudo tenían dificultades para analizar este tipo de habla.

- Daño representacional: Una herramienta de IA refuerza la subordinación de los grupos sociales en función de sus identidades

Ejemplo: Cuando se desarrolló por primera vez la tecnología de traducción, algunos resultados se inclinaban inexactamente hacia lo masculino o lo femenino. Por ejemplo, cuando se generaba una traducción de palabras como "enfermera" y "guapa", la traducción tenía un sesgo femenino. Cuando se utilizaban palabras como "médico" y "fuerte", la traducción era masculina.

- Daño al sistema social: Efectos sociales a nivel macro que amplifican las disparidades existentes de clase, poder o privilegio, o causan daños físicos, como resultado del desarrollo o uso de herramientas de IA

Ejemplo:  Los deepfakes no deseados, que son fotos o vídeos falsos generados por IA de personas reales diciendo o haciendo cosas que no dijeron ni hicieron, pueden ser un ejemplo de daño al sistema social.

- Daño interpersonal: El uso de la tecnología para crear una desventaja para determinadas personas que afecta negativamente a sus relaciones con los demás o provoca una pérdida de su sentido de sí mismas y de su agencia

Ejemplo: Si alguien fuera capaz de tomar el control de un dispositivo doméstico en su anterior apartamento para gastar una broma no deseada a su antiguo compañero de piso, estas acciones podrían provocar una pérdida del sentido de sí mismo y de la agencia por parte de la persona afectada por la broma.

### Deriva frente a corte de conocimiento

Otro fenómeno que puede causar resultados injustos o inexactos es la deriva. La deriva es la disminución de la precisión de las predicciones de un modelo de IA en debido a cambios a lo largo del tiempo que no se reflejan en los datos de entrenamiento. Por ejemplo, un diseñador de moda puede querer hacer un seguimiento de las tendencias de gasto antes de crear una nueva colección. Para empezar el seguimiento, utilizan un modelo creado en 2015 que se entrenó con las tendencias de la moda y los hábitos de consumo de 2015. Sin embargo, el modelo ya no es preciso porque los hábitos sociales y las tendencias de la moda cambian con el tiempo. Las preferencias de los consumidores en 2015 son diferentes de las tendencias actuales. En otras palabras, las predicciones del modelo han pasado de ser precisas en el momento del entrenamiento a ser menos precisas en la actualidad.

Del mismo modo, un límite de conocimiento es el concepto de que un modelo se ha entrenado en un punto específico en el tiempo, por lo que no tiene ningún conocimiento de eventos o información después de esa fecha. Por ejemplo, si le preguntas a una herramienta de IA generativa que fue entrenada en 2022 cuánto cuesta el último smartphone, el resultado del modelo no incluirá la tecnología más reciente de hoy en día: sólo conocerás los smartphones que existían en 2022. Por tanto, si los datos de un modelo no están actualizados, el resultado tampoco lo estará.

Afortunadamente, los límites de conocimiento no afectan a todos los datos de un modelo. Por ejemplo, un modelo de IA probablemente tendrá muchos datos relevantes sobre acontecimientos históricos, lugares famosos y obras literarias aclamadas. Pero a medida que utilice la IA, considere si las últimas investigaciones o los acontecimientos actuales podrían cambiar la precisión de sus resultados.


de Google PAIR Explorables. En él puedes interactuar con BERT, uno de los primeros modelos lingüísticos de gran tamaño (LLM), y explorar cómo las correlaciones en los datos pueden dar lugar a sesgos problemáticos en los resultados. También puedes consultar otros PIAR 
IA Explorables  para aprender más sobre IA responsable.
 

---
---

# IA para el bienestar social 

## :tv: Jalon: Mi trabajo en el equipo de IA responsable

Hola, me llamo Jalon. Este es mi nombre de señas, Jalon. Trabajo en Google desde hace algo más de tres años como analista de investigación en el departamento de Tecnología de uso responsable de la IA centrado en el humano. Parte de mi trabajo es poder continuar defendiendo a la comunidad sorda negra y asegurarme de que la comunidad sea escuchada. La mayor parte del tiempo en mi trabajo lidio con productos y herramientas que quizás no funcionen para mí y analizo cómo podemos mejorarlos. Queremos asegurarnos de que todas las personas estén incluidas cuando se desarrollan IA y productos, para garantizar que no haya ningún sesgo inconsciente en el proceso.

Ahora mismo, soy responsable de dirigir un proyecto llamado Comprender a los usuarios sordos negros. En este proyecto, el objetivo es captar realmente

la experiencia de los sordos negros y entender qué experimentan cuando los productos y la IA no les funcionan. Cómo es esa experiencia. Es muy importante porque si miras ahora mismo en la sociedad actual hay muchas industrias diferentes que intentan cambiar su enfoque sobre ASL y el reconocimiento del lenguaje de señas, pero se olvidan de la comunidad de sordos negros también. Sé de pocas personas que conocen gente que diría: "Ni siquiera puedo usar el producto para mí". Y si hemos dejado fuera a una o dos personas, aún nos queda mucho trabajo por hacer. La IA realmente puede ayudar a mejorar la vida de la comunidad sorda. Por ejemplo, cuando pensamos en la comunidad sorda, su lenguaje es el lenguaje de señas. Pero ¿qué ocurre cuando te encuentras con una comunidad o una población que no conoce el lenguaje de señas? La IA tiene la capacidad de tender puentes de comunicación para garantizar su efectividad y una comunicación eficaz. Pero es muy importante asegurarnos de que incluimos una igual cantidad de representaciones implicadas para que la IA sea precisa en todo momento. Cuantos más datos tengamos, más precisa será la experiencia para todos los que se sientan incluidos. Hay expertos sordos negros en este momento para abogar por la contratación de la comunidad de sordos negros comunidad. Como estás haciendo este curso de IA y pensando en cómo puedes influir en el mundo, va a ser muy importante que no sólo aprendas a entender la IA y el aprendizaje automático. La IA te va a exigir que pienses a conciencia en tu entorno. La IA no es sólo para una persona, es para una población enorme a la que intentamos llegar para que todos se sientan incluidos.


---
---

# Revisión: Utiliza la IA de forma responsable

---
---
